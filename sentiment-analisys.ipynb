{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analisys using BERT\n",
    "https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb  \n",
    "https://www.section.io/engineering-education/natural-language-processing-using-tensorflow-and-bert-model/#getting-started-with-bert  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers as ppb \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "#df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                                                       0  1\n",
       "0     a stirring , funny and finally transporting re...  1\n",
       "1     apparently reassembled from the cutting room f...  0\n",
       "2     they presume their audience wo n't sit still f...  0\n",
       "3     this is a visually stunning rumination on love...  1\n",
       "4     jonathan parker 's bartleby should have been t...  1\n",
       "...                                                 ... ..\n",
       "6915  painful , horrifying and oppressively tragic ,...  1\n",
       "6916  take care is nicely performed by a quintet of ...  0\n",
       "6917  the script covers huge , heavy topics in a bla...  0\n",
       "6918  a seriously bad film with seriously warped log...  0\n",
       "6919  a deliciously nonsensical comedy about a city ...  1\n",
       "\n",
       "[6920 rows x 2 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = df[1]\n",
    "plt.hist(labels)\n",
    "plt.xlabel('sentiment')\n",
    "plt.ylabel('nb samples')\n",
    "plt.title('sentiment distribution')\n",
    "plt.xticks(np.arange(len(np.unique(labels))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.TFDistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.TFBertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    tokenized = [tokenizer(sentence, add_special_tokens=True)['input_ids'] for sentence in sentences]\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenize(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
      "tokenized:  [101, 1037, 18385, 1010, 6057, 1998, 2633, 18276, 2128, 16603, 1997, 5053, 1998, 1996, 6841, 1998, 5687, 5469, 3152, 102]\n",
      "decoded:  [CLS] a stirring, funny and finally transporting re imagining of beauty and the beast and 1930s horror films [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(\"sentence: \", df[0][0] )\n",
    "print(\"tokenized: \", tokenized[0])\n",
    "print(\"decoded: \", tokenizer.decode(tokenized[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(tokens):\n",
    "    max_len = 0\n",
    "    for i in tokens:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence legth is  67\n"
     ]
    }
   ],
   "source": [
    "max_len = get_max_length(tokenized)\n",
    "print(\"Max sentence legth is \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(tokens, max_len):\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokens])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_tokens(tokenized, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  1037 18385  1010  6057  1998  2633 18276  2128 16603  1997  5053\n",
      "  1998  1996  6841  1998  5687  5469  3152   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of padded:  (6920, 67)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of padded: \", padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "If we directly send padded to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_mask(tokens):\n",
    "    attention_mask = np.where(tokens != 0, 1, 0)    \n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "attention_mask = get_attention_mask(padded)\n",
    "print(attention_mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.convert_to_tensor(padded, dtype=tf.int32)\n",
    "attention_mask = tf.convert_to_tensor(attention_mask, dtype=tf.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model() function runs our sentences through BERT. The results of the processing will be returned into last_hidden_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract features using batches for memory issue:\n",
      "Batch 1 [0:500]\n",
      "Batch 2 [500:1000]\n",
      "Batch 3 [1000:1500]\n",
      "Batch 4 [1500:2000]\n",
      "Batch 5 [2000:2500]\n",
      "Batch 6 [2500:3000]\n",
      "Batch 7 [3000:3500]\n",
      "Batch 8 [3500:4000]\n",
      "Batch 9 [4000:4500]\n",
      "Batch 10 [4500:5000]\n",
      "Batch 11 [5000:5500]\n",
      "Batch 12 [5500:6000]\n",
      "Batch 13 [6000:6500]\n",
      "Batch 14 [6500:6920]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "m = input_ids.shape[0]\n",
    "n = int(m / batch_size)\n",
    "\n",
    "hidden_units =  model.config.to_dict()['dim']\n",
    "features = np.zeros((m, hidden_units))\n",
    "\n",
    "print('Extract features using batches for memory issue:')\n",
    "\n",
    "for i in range(n):\n",
    "    j, k = i*batch_size, i*batch_size+batch_size\n",
    "    print(f'Batch {i+1} [{j}:{k}]')\n",
    "    batch_input = input_ids[j:k]\n",
    "    batch_attention_mask = attention_mask[j:k]\n",
    "    last_hidden_states = model(batch_input, attention_mask = batch_attention_mask)\n",
    "\n",
    "    #Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. \n",
    "    # The way BERT does sentence classification, is that it adds a token called [CLS] (for classification) at the beginning of \n",
    "    # every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
    "    features[j:k] = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "    ## if you use BERT instead of distilBERT model, use this\n",
    "    #features[j:k] = last_hidden_states[1].numpy() \n",
    "\n",
    "if(n*batch_size != m):\n",
    "    i = i + 1\n",
    "    j, k = i*batch_size, i*batch_size+(m-n*batch_size)\n",
    "    print(f'Batch {i+1} [{j}:{k}]')\n",
    "    batch_input = input_ids[j:k]\n",
    "    batch_attention_mask = attention_mask[j:k]\n",
    "    last_hidden_states = model(batch_input, attention_mask = batch_attention_mask)\n",
    "    features[j:k] = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "#print(\"last hidden tensor shape (n_samples, max_len, hidden_units): \"), last_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 768)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = df[1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of training data:  (5536, 768) (5536,)\n",
      "shapes of test data:  (1384, 768) (1384,)\n"
     ]
    }
   ],
   "source": [
    "# 80% train, 20% test\n",
    "split_size = int(features.shape[0] * .8)    \n",
    "X_train = features[:split_size,:]\n",
    "Y_train = lables[:split_size]\n",
    "X_test = features[split_size:,:]\n",
    "Y_test = lables[split_size:]\n",
    "\n",
    "print(\"shapes of training data: \", X_train.shape, Y_train.shape)\n",
    "print(\"shapes of test data: \", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, classes):\n",
    "    inputs = keras.Input(shape=input_shape, name='input')\n",
    "    #h1 = keras.layers.Dense(1024, activation='relu', name='h1')(inputs)    \n",
    "    #h2 = keras.layers.Dense(512, activation='relu', name='h2')(h1)\n",
    "    #h3 = keras.layers.Dense(32, activation='relu', name='h3')(h2)\n",
    "    d1 = keras.layers.Dropout(0.1, name='d1')(inputs)\n",
    "    outputs = keras.layers.Dense(classes, activation='sigmoid', name='output')(d1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "d1 (Dropout)                 (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lr_model = create_model(X_train.shape[1], 1)\n",
    "lr_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6554 - binary_accuracy: 0.6192 - val_loss: 0.6105 - val_binary_accuracy: 0.7265\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5803 - binary_accuracy: 0.7423 - val_loss: 0.5555 - val_binary_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5307 - binary_accuracy: 0.7764 - val_loss: 0.5205 - val_binary_accuracy: 0.7653\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4993 - binary_accuracy: 0.7949 - val_loss: 0.4943 - val_binary_accuracy: 0.7807\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4751 - binary_accuracy: 0.8047 - val_loss: 0.4753 - val_binary_accuracy: 0.7888\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4577 - binary_accuracy: 0.8096 - val_loss: 0.4610 - val_binary_accuracy: 0.7942\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4443 - binary_accuracy: 0.8216 - val_loss: 0.4496 - val_binary_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4347 - binary_accuracy: 0.8168 - val_loss: 0.4402 - val_binary_accuracy: 0.8078\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4252 - binary_accuracy: 0.8211 - val_loss: 0.4319 - val_binary_accuracy: 0.8060\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4194 - binary_accuracy: 0.8281 - val_loss: 0.4269 - val_binary_accuracy: 0.8042\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4120 - binary_accuracy: 0.8290 - val_loss: 0.4205 - val_binary_accuracy: 0.8177\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4064 - binary_accuracy: 0.8302 - val_loss: 0.4154 - val_binary_accuracy: 0.8150\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4023 - binary_accuracy: 0.8281 - val_loss: 0.4129 - val_binary_accuracy: 0.8105\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3975 - binary_accuracy: 0.8304 - val_loss: 0.4077 - val_binary_accuracy: 0.8159\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3921 - binary_accuracy: 0.8349 - val_loss: 0.4052 - val_binary_accuracy: 0.8204\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3904 - binary_accuracy: 0.8327 - val_loss: 0.4019 - val_binary_accuracy: 0.8204\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3861 - binary_accuracy: 0.8363 - val_loss: 0.4026 - val_binary_accuracy: 0.8231\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8385 - val_loss: 0.3988 - val_binary_accuracy: 0.8204\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3826 - binary_accuracy: 0.8351 - val_loss: 0.3947 - val_binary_accuracy: 0.8195\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3779 - binary_accuracy: 0.8399 - val_loss: 0.3928 - val_binary_accuracy: 0.8195\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3777 - binary_accuracy: 0.8367 - val_loss: 0.3917 - val_binary_accuracy: 0.8204\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3736 - binary_accuracy: 0.8399 - val_loss: 0.3896 - val_binary_accuracy: 0.8222\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3730 - binary_accuracy: 0.8363 - val_loss: 0.3894 - val_binary_accuracy: 0.8258\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3727 - binary_accuracy: 0.8363 - val_loss: 0.3874 - val_binary_accuracy: 0.8240\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3716 - binary_accuracy: 0.8406 - val_loss: 0.3864 - val_binary_accuracy: 0.8294\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3660 - binary_accuracy: 0.8433 - val_loss: 0.3848 - val_binary_accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8419 - val_loss: 0.3839 - val_binary_accuracy: 0.8267\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3664 - binary_accuracy: 0.8421 - val_loss: 0.3838 - val_binary_accuracy: 0.8330\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3635 - binary_accuracy: 0.8449 - val_loss: 0.3818 - val_binary_accuracy: 0.8285\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3614 - binary_accuracy: 0.8449 - val_loss: 0.3810 - val_binary_accuracy: 0.8285\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3593 - binary_accuracy: 0.8464 - val_loss: 0.3814 - val_binary_accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3587 - binary_accuracy: 0.8449 - val_loss: 0.3795 - val_binary_accuracy: 0.8267\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3599 - binary_accuracy: 0.8410 - val_loss: 0.3789 - val_binary_accuracy: 0.8285\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3574 - binary_accuracy: 0.8464 - val_loss: 0.3782 - val_binary_accuracy: 0.8276\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3556 - binary_accuracy: 0.8512 - val_loss: 0.3781 - val_binary_accuracy: 0.8285\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3594 - binary_accuracy: 0.8469 - val_loss: 0.3766 - val_binary_accuracy: 0.8321\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3519 - binary_accuracy: 0.8480 - val_loss: 0.3763 - val_binary_accuracy: 0.8294\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3553 - binary_accuracy: 0.8471 - val_loss: 0.3762 - val_binary_accuracy: 0.8303\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3533 - binary_accuracy: 0.8505 - val_loss: 0.3757 - val_binary_accuracy: 0.8312\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3541 - binary_accuracy: 0.8525 - val_loss: 0.3750 - val_binary_accuracy: 0.8312\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3513 - binary_accuracy: 0.8476 - val_loss: 0.3758 - val_binary_accuracy: 0.8303\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3531 - binary_accuracy: 0.8505 - val_loss: 0.3747 - val_binary_accuracy: 0.8276\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3504 - binary_accuracy: 0.8494 - val_loss: 0.3744 - val_binary_accuracy: 0.8312\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3511 - binary_accuracy: 0.8489 - val_loss: 0.3735 - val_binary_accuracy: 0.8330\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3480 - binary_accuracy: 0.8491 - val_loss: 0.3732 - val_binary_accuracy: 0.8321\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3464 - binary_accuracy: 0.8509 - val_loss: 0.3728 - val_binary_accuracy: 0.8330\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3458 - binary_accuracy: 0.8464 - val_loss: 0.3743 - val_binary_accuracy: 0.8330\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3446 - binary_accuracy: 0.8530 - val_loss: 0.3723 - val_binary_accuracy: 0.8330\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3448 - binary_accuracy: 0.8509 - val_loss: 0.3729 - val_binary_accuracy: 0.8312\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3434 - binary_accuracy: 0.8507 - val_loss: 0.3717 - val_binary_accuracy: 0.8321\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3469 - binary_accuracy: 0.8476 - val_loss: 0.3710 - val_binary_accuracy: 0.8357\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3471 - binary_accuracy: 0.8482 - val_loss: 0.3711 - val_binary_accuracy: 0.8348\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_accuracy: 0.8485 - val_loss: 0.3712 - val_binary_accuracy: 0.8321\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3401 - binary_accuracy: 0.8548 - val_loss: 0.3712 - val_binary_accuracy: 0.8339\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3437 - binary_accuracy: 0.8496 - val_loss: 0.3715 - val_binary_accuracy: 0.8330\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3431 - binary_accuracy: 0.8451 - val_loss: 0.3708 - val_binary_accuracy: 0.8321\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_accuracy: 0.8521 - val_loss: 0.3708 - val_binary_accuracy: 0.8321\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3450 - binary_accuracy: 0.8498 - val_loss: 0.3739 - val_binary_accuracy: 0.8394\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3442 - binary_accuracy: 0.8485 - val_loss: 0.3719 - val_binary_accuracy: 0.8357\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3432 - binary_accuracy: 0.8500 - val_loss: 0.3702 - val_binary_accuracy: 0.8330\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3393 - binary_accuracy: 0.8575 - val_loss: 0.3689 - val_binary_accuracy: 0.8330\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3389 - binary_accuracy: 0.8546 - val_loss: 0.3686 - val_binary_accuracy: 0.8348\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3403 - binary_accuracy: 0.8528 - val_loss: 0.3693 - val_binary_accuracy: 0.8339\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3375 - binary_accuracy: 0.8577 - val_loss: 0.3701 - val_binary_accuracy: 0.8330\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3372 - binary_accuracy: 0.8530 - val_loss: 0.3693 - val_binary_accuracy: 0.8312\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8539 - val_loss: 0.3684 - val_binary_accuracy: 0.8339\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3408 - binary_accuracy: 0.8525 - val_loss: 0.3685 - val_binary_accuracy: 0.8357\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3383 - binary_accuracy: 0.8561 - val_loss: 0.3700 - val_binary_accuracy: 0.8348\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3392 - binary_accuracy: 0.8528 - val_loss: 0.3683 - val_binary_accuracy: 0.8357\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3403 - binary_accuracy: 0.8523 - val_loss: 0.3689 - val_binary_accuracy: 0.8330\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3374 - binary_accuracy: 0.8541 - val_loss: 0.3682 - val_binary_accuracy: 0.8366\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3375 - binary_accuracy: 0.8530 - val_loss: 0.3685 - val_binary_accuracy: 0.8348\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3363 - binary_accuracy: 0.8579 - val_loss: 0.3696 - val_binary_accuracy: 0.8285\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3360 - binary_accuracy: 0.8579 - val_loss: 0.3681 - val_binary_accuracy: 0.8357\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3344 - binary_accuracy: 0.8534 - val_loss: 0.3680 - val_binary_accuracy: 0.8348\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3379 - binary_accuracy: 0.8503 - val_loss: 0.3680 - val_binary_accuracy: 0.8357\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3372 - binary_accuracy: 0.8528 - val_loss: 0.3675 - val_binary_accuracy: 0.8357\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3335 - binary_accuracy: 0.8559 - val_loss: 0.3675 - val_binary_accuracy: 0.8357\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3367 - binary_accuracy: 0.8530 - val_loss: 0.3689 - val_binary_accuracy: 0.8321\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3299 - binary_accuracy: 0.8620 - val_loss: 0.3676 - val_binary_accuracy: 0.8339\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3313 - binary_accuracy: 0.8561 - val_loss: 0.3673 - val_binary_accuracy: 0.8339\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3369 - binary_accuracy: 0.8550 - val_loss: 0.3670 - val_binary_accuracy: 0.8348\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3352 - binary_accuracy: 0.8525 - val_loss: 0.3670 - val_binary_accuracy: 0.8330\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3297 - binary_accuracy: 0.8579 - val_loss: 0.3674 - val_binary_accuracy: 0.8366\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3343 - binary_accuracy: 0.8555 - val_loss: 0.3676 - val_binary_accuracy: 0.8366\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3337 - binary_accuracy: 0.8530 - val_loss: 0.3676 - val_binary_accuracy: 0.8384\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3322 - binary_accuracy: 0.8552 - val_loss: 0.3668 - val_binary_accuracy: 0.8348\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3315 - binary_accuracy: 0.8541 - val_loss: 0.3673 - val_binary_accuracy: 0.8394\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3334 - binary_accuracy: 0.8568 - val_loss: 0.3674 - val_binary_accuracy: 0.8394\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3310 - binary_accuracy: 0.8577 - val_loss: 0.3670 - val_binary_accuracy: 0.8357\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3314 - binary_accuracy: 0.8561 - val_loss: 0.3676 - val_binary_accuracy: 0.8394\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3269 - binary_accuracy: 0.8579 - val_loss: 0.3675 - val_binary_accuracy: 0.8330\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3311 - binary_accuracy: 0.8543 - val_loss: 0.3668 - val_binary_accuracy: 0.8403\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3276 - binary_accuracy: 0.8575 - val_loss: 0.3665 - val_binary_accuracy: 0.8366\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3296 - binary_accuracy: 0.8591 - val_loss: 0.3664 - val_binary_accuracy: 0.8375\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3286 - binary_accuracy: 0.8541 - val_loss: 0.3679 - val_binary_accuracy: 0.8366\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3285 - binary_accuracy: 0.8589 - val_loss: 0.3689 - val_binary_accuracy: 0.8375\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3270 - binary_accuracy: 0.8566 - val_loss: 0.3665 - val_binary_accuracy: 0.8375\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3267 - binary_accuracy: 0.8622 - val_loss: 0.3674 - val_binary_accuracy: 0.8384\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3314 - binary_accuracy: 0.8559 - val_loss: 0.3656 - val_binary_accuracy: 0.8357\n"
     ]
    }
   ],
   "source": [
    "history = lr_model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.328643</td>\n",
       "      <td>0.854110</td>\n",
       "      <td>0.367893</td>\n",
       "      <td>0.836643</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.328510</td>\n",
       "      <td>0.858853</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.837545</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.326989</td>\n",
       "      <td>0.856594</td>\n",
       "      <td>0.366452</td>\n",
       "      <td>0.837545</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.862240</td>\n",
       "      <td>0.367375</td>\n",
       "      <td>0.838448</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.331380</td>\n",
       "      <td>0.855917</td>\n",
       "      <td>0.365569</td>\n",
       "      <td>0.835740</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  binary_accuracy  val_loss  val_binary_accuracy  epoch\n",
       "95  0.328643         0.854110  0.367893             0.836643     95\n",
       "96  0.328510         0.858853  0.368902             0.837545     96\n",
       "97  0.326989         0.856594  0.366452             0.837545     97\n",
       "98  0.326733         0.862240  0.367375             0.838448     98\n",
       "99  0.331380         0.855917  0.365569             0.835740     99"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df['epoch'] = history.epoch\n",
    "history_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa850250f60>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4IUlEQVR4nO3dd3xUZdr/8c81k95JSCgJIaF3AoQiWFBRsSxYUEFXYd0V3bXsuq4+uk0ffdxn3fW3Xd1FxbYq+lhYVBRFwYZKE5FeAyRAEtJ7Msn1++MMIUAIATIMZK736zUvMqdeJ6PzzX3uc+4jqooxxhhzKJe/CzDGGHNqsoAwxhjTLAsIY4wxzbKAMMYY0ywLCGOMMc0K8ncBbaVjx46alpbm7zKMMea0smLFin2qmtjcvHYTEGlpaSxfvtzfZRhjzGlFRHYcaZ6dYjLGGNMsCwhjjDHNsoAwxhjTrHbTB2ECT11dHdnZ2VRXV/u7lHYjLCyMlJQUgoOD/V2KOQVYQJjTVnZ2NtHR0aSlpSEi/i7ntKeqFBQUkJ2dTXp6ur/LMacAO8VkTlvV1dUkJCRYOLQRESEhIcFaZKaRBYQ5rVk4tC37fZqmAj4gSqvr+POHm1i1q9jfpRhjzCnFpwEhIhNFZKOIbBGR+46wzDUisk5E1orIy02m14vIKu9rnq9qbGhQ/vrRZlbsKPLVLkw7VVBQQEZGBhkZGXTu3Jnk5OTG97W1tS2uu3z5cu68886j7mPs2LFtVa4xx8xnndQi4gYeBy4AsoFlIjJPVdc1WaY3cD8wTlWLRCSpySaqVDXDV/XtFx3mXK1RUtny/9DGHCohIYFVq1YB8OCDDxIVFcUvfvGLxvkej4egoOb/F8vMzCQzM/Oo+1iyZEmb1GrM8fBlC2IUsEVVt6lqLTAHmHzIMjcDj6tqEYCq5vmwnma5XUJMWBAlVXUne9emHZoxYwa33noro0eP5t5772Xp0qWcccYZDBs2jLFjx7Jx40YAFi9ezGWXXQY44XLTTTcxfvx4evTowd/+9rfG7UVFRTUuP378eKZMmUK/fv24/vrr2f80yPnz59OvXz9GjBjBnXfe2bhdY06ULy9zTQZ2NXmfDYw+ZJk+ACLyBeAGHlTV973zwkRkOeABfq+qc31VaGxEsAXEae6/317Lut2lbbrNAV1jeOB7A495vezsbJYsWYLb7aa0tJTPPvuMoKAgFi5cyC9/+UveeOONw9bZsGEDixYtoqysjL59+/LjH//4sHsRvvnmG9auXUvXrl0ZN24cX3zxBZmZmdxyyy18+umnpKenM23atOM+XmMO5e/7IIKA3sB4IAX4VEQGq2ox0F1Vc0SkB/CxiHynqlubriwiM4GZAKmpqcddRFx4CMUWEKaNXH311bjdbgBKSkqYPn06mzdvRkSoq2v+v7NLL72U0NBQQkNDSUpKIjc3l5SUlIOWGTVqVOO0jIwMsrKyiIqKokePHo33LUybNo1Zs2b58OhMIPFlQOQA3Zq8T/FOayob+FpV64DtIrIJJzCWqWoOgKpuE5HFwDDgoIBQ1VnALIDMzEw93kJjw60Fcbo7nr/0fSUyMrLx59/85jece+65vPXWW2RlZTF+/Phm1wkNDW382e124/F4jmsZY9qSL/sglgG9RSRdREKAqcChVyPNxWk9ICIdcU45bRORDiIS2mT6OGAdPhIbHkxJpQWEaXslJSUkJycD8Nxzz7X59vv27cu2bdvIysoC4NVXX23zfZjA5bOAUFUPcDuwAFgPvKaqa0XkIRGZ5F1sAVAgIuuARcA9qloA9AeWi8i33um/b3r1U1uzPgjjK/feey/3338/w4YN88lf/OHh4TzxxBNMnDiRESNGEB0dTWxsbJvvxwQm2X8lxOkuMzNTj/eBQY++v4GnPt3G5kcutjtJTyPr16+nf//+/i7D78rLy4mKikJVue222+jduzd33XXXcW/Pfq+BRURWqGqz11wH/J3UAHHhwXgalIraen+XYswxe+qpp8jIyGDgwIGUlJRwyy23+Lsk0074+yqmU0JsuPdmuao6okLtV2JOL3fdddcJtRiMORJrQQBxEU5AFNvd1MYY08gCAohp0oIwxhjjsIDgwCmmUgsIY4xpZAEBxEWEAFBs90IYY0wjCwgO7qQ2prXOPfdcFixYcNC0v/zlL/z4xz9udvnx48ez/1LsSy65hOLi4sOWefDBB3nsscda3O/cuXNZt+7AbUG//e1vWbhw4TFWb8zRWUAAkSFuglxi4zGZYzJt2jTmzJlz0LQ5c+a0asC8+fPnExcXd1z7PTQgHnroISZMmHBc2zKmJRYQOI9ZtPGYzLGaMmUK7777buPDgbKysti9ezevvPIKmZmZDBw4kAceeKDZddPS0ti3bx8AjzzyCH369OHMM89sHA4cnPsbRo4cydChQ7nqqquorKxkyZIlzJs3j3vuuYeMjAy2bt3KjBkzeP311wH46KOPGDZsGIMHD+amm26ipqamcX8PPPAAw4cPZ/DgwWzYsMGXvxrTTthF/1423EY78Oylh08beDmMuhlqK+Glqw+fn3EdDLseKgrgtRsPnveDd1vcXXx8PKNGjeK9995j8uTJzJkzh2uuuYZf/vKXxMfHU19fz/nnn8/q1asZMmRIs9tYsWIFc+bMYdWqVXg8HoYPH86IESMAuPLKK7n55psB+PWvf80zzzzDHXfcwaRJk7jsssuYMmXKQduqrq5mxowZfPTRR/Tp04cbb7yRJ598kp/97GcAdOzYkZUrV/LEE0/w2GOP8fTTT7d4fMZYC8LLBuwzx6Ppaab9p5dee+01hg8fzrBhw1i7du1Bp4MO9dlnn3HFFVcQERFBTEwMkyZNapy3Zs0azjrrLAYPHsxLL73E2rVrW6xl48aNpKen06dPHwCmT5/Op59+2jj/yiuvBGDEiBGNg/sZ0xJrQXjFhgdTUG43yp3WWvqLPySi5fmRCUdtMTRn8uTJ3HXXXaxcuZLKykri4+N57LHHWLZsGR06dGDGjBlUV1cf83bBeTrd3LlzGTp0KM899xyLFy8+ru3st3+4cBsq3LSWtSC84sKDKa6ygDDHJioqinPPPZebbrqJadOmUVpaSmRkJLGxseTm5vLee++1uP7ZZ5/N3LlzqaqqoqysjLfffrtxXllZGV26dKGuro6XXnqpcXp0dDRlZWWHbatv375kZWWxZcsWAF588UXOOeecNjpSE4gsILzsFJM5XtOmTePbb79l2rRpDB06lGHDhtGvXz+uu+46xo0b1+K6w4cP59prr2Xo0KFcfPHFjBw5snHeww8/zOjRoxk3bhz9+vVrnD516lT++Mc/MmzYMLZuPfAMrbCwMJ599lmuvvpqBg8ejMvl4tZbb237AzYBw4b79vrTh5v4+8eb2fLIJbhdNuT36cCGpfYN+70GFhvuuxViw4NRhbJqa0UYYwxYQDSKs7upjTHmIBYQXjbcxumpvZwiPVXY79M0ZQFRVwUvXE6PPe8ANmDf6SQsLIyCggL7UmsjqkpBQQFhYWH+LsWcIuw+iKAw2PEFcTH9gM7WgjiNpKSkkJ2dTX5+vr9LaTfCwsJISUnxdxnmFGEBIQJRnQivLQCwAftOI8HBwaSnp/u7DGPaLZ+eYhKRiSKyUUS2iMh9R1jmGhFZJyJrReTlJtOni8hm72u6L+skMpGQauevUHtokDHGOHzWghARN/A4cAGQDSwTkXmquq7JMr2B+4FxqlokIkne6fHAA0AmoMAK77pFPik2qhPukmzCgl12iskYY7x82YIYBWxR1W2qWgvMASYfsszNwOP7v/hVNc87/SLgQ1Ut9M77EJjos0o7D4YO3YkLD6G40obbMMYY8G1AJAO7mrzP9k5rqg/QR0S+EJGvRGTiMazbds77FUx9yZ4JYYwxTfi7kzoI6A2MB1KAT0VkcGtXFpGZwEyA1NTUEy4mNiLYLnM1xhgvX7YgcoBuTd6neKc1lQ3MU9U6Vd0ObMIJjNasi6rOUtVMVc1MTEw8/kqzvoB/jKK/O8daEMYY4+XLgFgG9BaRdBEJAaYC8w5ZZi5O6wER6YhzymkbsAC4UEQ6iEgH4ELvNN9wuWHfRpLdRXYVkzHGePnsFJOqekTkdpwvdjcwW1XXishDwHJVnceBIFgH1AP3qGoBgIg8jBMyAA+paqGvaiUqCYDOUmz3QRhjjJdP+yBUdT4w/5Bpv23yswI/974OXXc2MNuX9TWKdAIigWIqa+up9TQQEmSjkBhjApt9CwKERkFwJB20GLAB+4wxBiwgDuh3KZ7Y7oAFhDHGgAXEAVc9RdGgHwAWEMYYAxYQBznwTAi7m9oYYywg9lv0vwx8zXnAvLUgjDHGAuIAl5vgsmxCqLO7qY0xBguIA7z3QnSUUoosIIwxxgKiUVQnAHpHVJJXWu3nYowxxv8sIPbztiB6RpSTawFhjDEWEI1iu8GQqbijksgtrfF3NcYY43cWEPtFJcGV/6IiaZi1IIwxBguIg6nSJTKIgopaaj0N/q7GGGP8ygKiqVnncPm23wCQV2atCGNMYLOAaCo0hmiPM6q49UMYYwKdBURTUZ2IqC0AsH4IY0zAs4BoKiqJ4Kp8wALCGGMsIJqKSkLqKoh117LXAsIYE+AsIJpKPQPO/DmdooPJsz4IY0yA8+kjR087qWMgdQzRm5fYKSZjTMCzFkRTqlBVRPcotVNMxpiAZwHRVHkePJrG+bUf2SkmY0zA82lAiMhEEdkoIltE5L5m5s8QkXwRWeV9/ajJvPom0+f5ss5GkR1B3HSVQsprPJTXeE7Kbo0x5lTksz4IEXEDjwMXANnAMhGZp6rrDln0VVW9vZlNVKlqhq/qa5bLDR26k+TJAZxLXaMSo05qCcYYc6rwZQtiFLBFVbepai0wB5jsw/21jYRexFXtAiC3xPohjDGBy5cBkQzsavI+2zvtUFeJyGoReV1EujWZHiYiy0XkKxG53Id1Hiy+J+FlWYCSa+MxGWMCmL87qd8G0lR1CPAh8HyTed1VNRO4DviLiPQ8dGURmekNkeX5+fltU9HAy6mb8AhB1LO3xDqqjTGBy5cBkQM0bRGkeKc1UtUCVd3/Lfw0MKLJvBzvv9uAxcCwQ3egqrNUNVNVMxMTE9um6tQxhI75IeGhYXYvhDEmoPkyIJYBvUUkXURCgKnAQVcjiUiXJm8nAeu90zuISKj3547AOODQzm3faGiA3LUMjiq2gDDGBDSfXcWkqh4RuR1YALiB2aq6VkQeApar6jzgThGZBHiAQmCGd/X+wL9EpAEnxH7fzNVPvjPrXK4L/x6zS1NO2i6NMeZU49OhNlR1PjD/kGm/bfLz/cD9zay3BBjsy9qOyOWC+B6kVe2xZ0IYYwKavzupT00JPensySGvrJqGBvV3NcYY4xcWEM1J6EmHmhzq6+spqqz1dzXGGOMXFhDNSeiFW+voKvts0D5jTMCygGhOz/PZcsGzFGqMDdpnjAlYFhDNiU0mfODFVBJmLQhjTMCygDiCpLwvGS3r7V4IY0zAsoA4guCPH+CnYe+wq7DK36UYY4xfWEAcSUIverj2siW/3N+VGGOMX1hAHElCT5Lqc9mRV4yq3QthjAk8FhBHEt8TFw3E1+62jmpjTECygDiShF4ApMleNufaaSZjTOCxgDiSzoMomr6ILxoGsSXPAsIYE3gsII4kOJy4tGGER0Sy2QLCGBOALCBaINsWcXfEe2zJK/N3KcYYc9JZQLRk22KmVbzI9ly7kskYE3gsIFrSZShBWkdidRYFFTaqqzEmsFhAtKTzUAAGubbblUzGmIBjAdGS+B40BEcyULLsjmpjTMCxgGiJy4V0GUKqu5AtudZRbYwJLD59JnV7IDe8xV9nrSTKWhDGmABjLYijCQ6nV2KU9UEYYwKOBcTRVBbyk/yHGVyxhJKqOn9XY4wxJ41PA0JEJorIRhHZIiL3NTN/hojki8gq7+tHTeZNF5HN3td0X9bZotAY0go/ZYxrvQ25YYwJKD4LCBFxA48DFwMDgGkiMqCZRV9V1Qzv62nvuvHAA8BoYBTwgIh08FWtLXIH4ek4gEGSZXdUG2MCSqsCQkR+KiIx4nhGRFaKyIVHWW0UsEVVt6lqLTAHmNzKui4CPlTVQlUtAj4EJrZy3TYXnDKMga4sNu+1gDDGBI7WtiBuUtVS4EKgA3AD8PujrJMM7GryPts77VBXichqEXldRLody7oiMlNElovI8vz8/FYeyrFzdR1KjFSyL3uTz/ZhjDGnmtYGhHj/vQR4UVXXNpl2It4G0lR1CE4r4fljWVlVZ6lqpqpmJiYmtkE5R9B1GDnhfdm9dy8NDTYmkzEmMLQ2IFaIyAc4AbFARKKBhqOskwN0a/I+xTutkaoWqGqN9+3TwIjWrntSdRnKkvPfYGlNKtv2WUe1MSYwtDYgfgjcB4xU1UogGPjBUdZZBvQWkXQRCQGmAvOaLiAiXZq8nQSs9/68ALhQRDp4O6cv9E7zm4xucbipZ9WuEn+WYYwxJ01rA+IMYKOqFovI94FfAy1+U6qqB7gd54t9PfCaqq4VkYdEZJJ3sTtFZK2IfAvcCczwrlsIPIwTMsuAh7zT/KZnzly+Cb2F9Vn+a8gYY8zJ1NqhNp4EhorIUOBunNNBLwDntLSSqs4H5h8y7bdNfr4fuP8I684GZreyPp9zxaUSI5Xoji9wrr41xpj2rbUtCI86T8yZDPxDVR8Hon1X1ikodQx1rlC6F31NdV29v6sxxhifa21AlInI/TiXt74rIi6cfojAERRKceJIxsp3rN9T6u9qjDHG51obENcCNTj3Q+zFuarojz6r6hQV2ncCvV05bNq80d+lGGOMz7UqILyh8BIQKyKXAdWq+oJPKzsFxQz5HrPc17Jmj13qaoxp/1o71MY1wFLgauAa4GsRmeLLwk5JHXuxvPtMPt9rj9EwxrR/rf2m+xXOPRB5ACKSCCwEXvdVYaeqEV1DqdnwAcUVY4iLDPN3OcYY4zOt7YNw7Q8Hr4JjWLddObfhS54PeZSt333l71KMMcanWvsl/76ILPA+v2EG8C6H3N8QKLoMcwaVrd6w0M+VGGOMb7XqFJOq3iMiVwHjvJNmqepbvivr1BWdmMo2V3cS9nzi71KMMcanWt3bqqpvAG/4sJbTRlbSBMbvmU11wU7CElL9XY4xxvhEi6eYRKRMREqbeZWJSMDeLRaROQ2XKDu+tLw0xrRfLQaEqkarakwzr2hVjTlZRZ5qMoYOZ1L9H3jZM8HfpRhjjM8E5JVIJyos2E1iz+F8vCkfZ4gqY4xpfywgjtO5fRP5UekTFCw42pNXjTHm9GQBcZzO7d+JVMkj9JvnoOFoD9czxpjTjwXEcUqOC2dp9ASia/bCzi/9XY4xxrQ5C4gTEDzwe1RoKLXfvOzvUowxps1ZQJyAswZ2572G0bjWvAlVxf4uxxhj2pQFxAkY1i2O19yXsTRmAtTX+rscY4xpUxYQJyDI7SKl/2huLfo+1aEJ/i7HGGPalAXECZoyIoXS6jqWfvoeZH3h73KMMabN+DQgRGSiiGwUkS0icl8Ly10lIioimd73aSJSJSKrvK9/+rLOEzGmRwKpHcLo+eV98P59YDfOGWPaCZ8FhIi4gceBi4EBwDQRGdDMctHAT4GvD5m1VVUzvK9bfVXniXK5hCmZ3flH1YWwdzVkfebvkowxpk34sgUxCtiiqttUtRaYA0xuZrmHgUeBah/W4lNXjUjhrYazqAzuAEv+7u9yjDGmTfgyIJKBXU3eZ3unNRKR4UA3VX23mfXTReQbEflERM5qbgciMlNElovI8vz8/DYr/Fglx4UzsldXXtSLYfMHsNOeNmeMOf35rZNaRFzAn4C7m5m9B0hV1WHAz4GXReSw0WNVdZaqZqpqZmJiom8LPoprMrvxl/IJVMb0hJJsv9ZijDFtwZcBkQN0a/I+xTttv2hgELBYRLKAMcA8EclU1RpVLQBQ1RXAVqCPD2s9YRcO7ERoRDT/1WkWDJ7i73KMMeaE+TIglgG9RSRdREKAqcC8/TNVtURVO6pqmqqmAV8Bk1R1uYgkeju5EZEeQG9gmw9rPWGhQW6mDE9h/to8tueXwbp5UO/xd1nGGHPcfBYQquoBbgcWAOuB11R1rYg8JCKTjrL62cBqEVkFvA7cqqqFvqq1rdxyTk9Cg1y8O/cVeO0G+OZFf5dkjDHHTdrLA28yMzN1+fLl/i6D//fBRv7+8WbWdv8TkeW74I7lEBbr77KMMaZZIrJCVTObm2d3Urexm8/uQVxECH/gB1CRDx8/4u+SjDHmuFhAtLGYsGB+Mr4nz++IZ2+f62HZU7B7lb/LMsaYY2YB4QM3npFG55gw7i6chCaPgNpyf5dkjDHHzALCB8KC3fxsQm++yPbwwZgXIe1Mf5dkjDHHzALCR6aMSKFnYiR/WLART3UFLP495Kzwd1nGGNNqFhA+EuR2ce/EfmzNr+Ddr9fCqpfhhcth11J/l2aMMa1iAeFDFw7oxPDUOB75vJTq778NkR3hxStgxxJ/l2aMMUdlAeFDIsJ9F/cnr6yGZ76rgxnzIboL/Psq2LPa3+UZY0yLLCB8bFR6PBP6J/Hk4q1sroqCGe9AbAqU7fV3acYY0yILiJPgwUkDCQ9xM+PZZeRqHPz4S+hzob/LMsaYFllAnAQpHSJ4dsZIiipr+cGzyyjfP4bf0qfgw9/6tTZjjDkSC4iTZFByLE9cP5yNuWX85KWV1DcoFGyBL/7qvIwx5hRjAXESje+bxP9cPohPN+Xzz0+2woWPwMArnVaEParUGHOKCfJ3AYFm6shufL5lH39ZuIlz+iQy6MqnAIUPfg0IjL3d3yUaYwxgLYiTTkR45PJBdIgI4a5XV1HdIHDl0zDgcsA79HpDA7STYdiNMacvCwg/iIsI4Q9ThrA5r5zHFmwEdxBc/RyMvcNZ4JsXYPZEKDylH6JnjGnnLCD8ZHzfJG4Y051nvtjO/O/2gMiBmSFRsG8jPD8Jinb4r0hjTECzgPCjX13anxGpHfjZnFUs2brvwIzBU+DG/0BNKTx/GRTv8l+RxpiAZQHhR2HBbp6enklaxwhmvrCCNTklB2Z2GQo3zIWqEnhlqtMvYYwxJ5EFhJ/FRYTw/E2jiAkLYsazy1i/p/TAzOThcMObTge2y+V0XOdt8FutxpjAYgFxCugSG84LPxyF2wVXPrGEd1fvOTAzJRPOucf5eevH8MRoeHMmVOxrfmPGGNNGfBoQIjJRRDaKyBYRua+F5a4SERWRzCbT7veut1FELvJlnaeCXknRvH37mfTvEs1tL6/ksQUbaWg45FLXlEw46xew5k34x0hY9QpUFByYX1t5cos2xrRrPgsIEXEDjwMXAwOAaSIyoJnlooGfAl83mTYAmAoMBCYCT3i3164lxYTxyswxXJvZjX8s2sJdr62irr5J30NYLJz/G7j1M+jYG+beCm/f6cwryYa/ZcCXT9g9FMaYNuHLFsQoYIuqblPVWmAOMLmZ5R4GHgWqm0ybDMxR1RpV3Q5s8W6v3QsNcvP7qwZzz0V9+c+q3dzy4gqqausPXiipP/zgfefeieE3OtOCIyB5BCy43+nUbtqyMMaY4+DLgEgGml6fme2d1khEhgPdVPXdY13Xu/5MEVkuIsvz8/PbpupTgIhw27m9+N0Vg1m0MY8bZ39NaXXdwQu5XDDwCujjPfsWEQ9TX4aJjzp9FbPG20OJjDEnxG+d1CLiAv4E3H2821DVWaqaqaqZiYmJbVfcKeK60an8fdowVu0q5qZnl1FZ62l5BREYcyvctAC0Hr58/OQUaoxpl3w5WF8O0K3J+xTvtP2igUHAYnHuIu4MzBORSa1YN2BcNqQrLhFuf3klM19YwdPTMwkLPkp3TPJwmLkYQiKd9zu/BnE5ndxN79g2xpgW+LIFsQzoLSLpIhKC0+k8b/9MVS1R1Y6qmqaqacBXwCRVXe5dbqqIhIpIOtAbWOrDWk9plwzuwh+mDOXzLfu445VvDu64PpKopAMBsfh/4ZkJ8PcRsPC/YeP7dpmsMeaofNaCUFWPiNwOLADcwGxVXSsiDwHLVXVeC+uuFZHXgHWAB7hNVeuPtHwgmDIihYoaDw/MW8vo333ExEGduWxIF8akJ+ByHaVVcM0LsH4efDvHeTiR1kP62TD9bWd+fR24g31/EMaY04poO7kkMjMzU5cvX+7vMnxu8cY8Xl+RzUfr86iqq+fMXh15/LrhxEa08gu+thJ2f+P8nDYOKgvh8VHQY7xzGW1QGER2hMHXQOxh1wUYY9oZEVmhqpnNzbMHBp1mxvdNYnzfJCprPfzf8mz+5911XP7EFzw9PZOeiVFH30BIhBMM+9VVQo9zYccX4KkGTw3UlkOHNIi9AsrzocEDMV18dkzGmFOTtSBOc8uyCrnlxRV46ht4+PJBXDakK+6jnXI6muKdENUZgkLgkz/Cov9x3icPh57nQZ+JENft6NsxxpzyWmpBWEC0A7sKK7n13ytYu7uUXklR3HFer7YJCoC89bBtMexeBbu+gqIsCAqH/8qC4DDnngtVCI1xHnwUFAYJvZ2fjTGnPAuIAFDfoLy3Zg9//2gLG3PLiAoNYnByLEO7xXHp4C4MTok98Z2owr7NkL8eBnhvin/qPMhZcfByyZlw80cnvj9jjM9ZQASQhgZl4fpcPtu8j2+zi1m/pxRB+MvUDC4Z7IN+hIp9kL/R6cuor4PqEnC5Ycg14KmFf50N8T0goYdzL0ZlgTN8ee8L2r4WY8wxs07qAOJyCRcO7MyFAzsDUFxZyw+fX85tL6/kocmDuGFM97bdYWRH59Wc2nLo2Av2bYEtHwLiDAnSdZgzf+93MPcn0Ot8iEuF2G5O53iHNLvs1phTgAVEOxcXEcK/fzia219eyW/mruGrrQV0iQ0jMjSIgV1jGoPEJyLi4dp/Oz/vb6k2vZO7psxpbSz5u3Ol1H4zFzshsuYNWPYMjcHS+0Jn7KmoJN/VbIxpZAERAMJD3PzrhhE8/M465q/ZS0WNh0rvCLHTRnXjwUkDCQ3y8WjqzQ3x0X2sEwYN9VC2F0p2OZ3gHfs0XdH5J2elc7OfuOGeLU5gLHsaslc4p64EcAU7V1ed5R3eq7IQQqOd1oinFoq2Q9ke554PY8xRWR9EgKqrb+AvCzfx+KKtZHSL48nvD6dLbLi/yzoyVeeUVM4KyPyBM+29+2D924A68+trICQKfuYdxfbfV8HWRU6LozzPuYM8dSzc9J4z/527oLbCuQIrLAbiukPKSOh02GNLDle4zbnCq9cECAr1ySG3SnUJIE79xhwH66Q2R/T+mj3c/dq3VHsa6BwTRnJcOJ1iw4gNDyImLJj4yBAGJccyODmWyNDToMFZ7zlwie36t53Lc0t3Q0xX5yFLXYdDYh8nUJ69GEpznFNd1aVOgAyZClf+y5n/9+EQHAnhcRCZ6PS1DLjcudEwfxM8PhLC42HoVEg7E8pzYeh1zuW/ZblOyybKR6MMe2rhy3/AJ39w3g+Y7DxMKjbFN/sz7ZYFhGnR1vxy3lyZze7ianKKq8gtraa0qo6yag8e72NPXQKDkmP587UZrbtj+3TT0ADFWU4wJPR0rsj6z21OcFQVQUW+c8XWsOth4v86y2/5EFa9DBvehQbv8zruWOms/+FvnXGv4ro7V3HFpUKH7gdOf615E/Z86+ynvhZQ53TYhAed+Yt+Bzu/ckIpLtV5xSQ7fTDVJfD0BbBvI/S7DKI6wbr/wO3LnFNvu5Y5IdVpkI3ea47KAsIcF1WloKKW1dnFrNpVwktf7SA0yMXrPx5L17hT+HTUyVZR4PRvRHeB6M5Ox/veNbBlIexZ5dyZXrQD6qrgV7uddd642flSd4c4LR5xOa2U27xP3l3wK9i11AmmkmwngJIGwk+WOPPfv9/pS9n/wKimLafnLoOsz5yrwdLOcl6pY5yAAqgqdvp6irZDwVbYt8mZn3mTE5Dz73FCrtNAJ2Qi4g8ca32dE1yb3oesz535A6+AHuc4fT21lU6rLCTKCS7XIQNGVxU5pwmzVzi/p57nQZeMw5drLU+N03KLSz2+9U9lDQ1QU+q0YH3IAsK0iTU5JUyb9RVJMaH8361jiY8MQVXJK6shLiLY9x3dp7umX+LHYn8nvta37ouwYp/Tob95Iez43Glx9L4Irn/Nmf9YXyjfe2D5mBTn0bXj/8tZ9x+Zzhf5flGd4PzfwrDvw/bP4PnLnGBLHuEEYW0Z3PIpdBnq9At9/aSzXlCYU29ozIEbJ+dcDxvewbmqwPvd03U4zFzk/Pzu3U4NLje4vHfmdxvl7Buc04aeGud+mq2LYPuncMZP4LxfO+G08nmn3tBoJ6RCo50awmKc3399jRPG1SXeVmE+dB4KkQlQuB22f+L8vrUBwuIgsa/zCgp1+qtKdzu/G0+1c5oPnIstQiKciyIKtzkXW5TnO6HnCoaM65zwPNrnX18HO7+EzR86IbpntTPq8rSXnfmeWmf4m9pKyN8AEQkHQv8E2H0Qpk0MSo7lqemZTJ+9lOue+oousWF8m11CYUUtLoHkDuH06BjF1ZkpXDq4C2KnNw52vMOPuNzHNrJuZEenNZB5k/Nll7sG6po88v3sXzgtnQ5p0CEdQqMOXvfe7U6nfu53TgAUbHaWB6elce2/ndZLaLSz3azPofMQZ/7gq6FrhnMPTFGW82pocFomIjDupzBqpnMZs6cGti1yvhj3K9zmbTHVO5c+11U5N2HuD4j/3A7Vxc7PHdIgYxoMudZ5n7Mc3r/v8N/HlNkw6CrI+hRevOLw+Te85bRk9nwLb//08Pk/XAjdRsLy2fDBrw+ff9daJyC+/Ad89v8Onz90qvPvB7+C1a9CeAcnNEOjnRGUp77kzH9hsjNopjvECdv9fVvgtECfOs9Zt3CrE2AA33/TuY/IR6wFYY7ZwnW53PP6tyRGh5LRLY7+XWIoqqwja18Fq7OLySqoZHhqHL+6dAAjunfwd7nmdLc/XMAZ6gUgOKL50Czb6/yFX1PunJ6pLXeGfolNdr5k177lbR3EOKf0IjpC50HOF3VtpbOuy+1cTl25z/lLvdcFTojmb3T+qg/v4LQogsKcbSUPd1oIeeudfcSmOK0YbXBODcYkO/Wvm+eMa1ZT6vRt1ZQ5LYIb/+PUvuFd51h7jD84tMEJzo8fcVounQY5V9oVZTlhG3xip3vtFJNpc6rabAuhvkF5Y0U2f/xgI/llNZzdJ5EZY7szvk/S0R9sZIw56SwgzElXUeNh9ufbefGrHeSV1ZAaH8H1o1O5akQKHaP8eN+AMeYgFhDGb+rqG1iwdi8vLNnB0qxCgt3ChQM6c06fRJI7hJMcF05xVR3f7Czim53FRIUF8aMz0+lxhEtpt+WX811OCZOGdrU+DmPagHVSG78Jdru4bEhXLhvSlS15ZbyydBdvrszm3e/2HLZsl9gwCitqmbN0J5cO6cotZ/dgYNeYxiB4Y0U2v567hqo6Z5iQyRn2SFRjfMlaEOak89Q3sKekml1FleQUVREZGsSw1Di6xIaTX1bDM59v58Uvs6ioradXUhTfG9KVXUWVvL4im9Hp8VR7GsjaV8EHd51Np5gwfx+OMac1O8VkTjsllXW8vXo3b3+7m6VZhQDccW4v7jy/N7uKqrj4r58ypkcCz84YSWVtPY++v4G3VuZwZu+OXDuyG2f1TqRBlV2FleSW1jC8e5zdp2FMM/wWECIyEfgr4AaeVtXfHzL/VuA2oB4oB2aq6joRSQPWAxu9i36lqre2tC8LiPZrb0k1VXX1pHeMbJz2/JIsHpi3lh+MS2Ph+lyyi6qY0L8TK3YUUVhRS2x4MOU1Huq9Q4WkdAjnnov68r0hXalraODTTfv4eEMew1PjuHJ4Sts8ntWY05BfAkJE3MAm4AIgG1gGTFPVdU2WiVHVUu/Pk4CfqOpEb0C8o6qDWrs/C4jA0tCgfP+Zr1mytYC0hAj+MGUoo9LjqfHUs3BdHos35pEUE0p6xyjCgl08vmgr6/eU0qdTFHtLqimt9hAS5KLW00CvpCh+cWEfuidEkrWvgp2FlWR0i2N0jwR/H6YxPuevTupRwBZV3eYtYg4wGWgMiP3h4BVJ4733xrTM5RL+OnUY76/dy5ThKYSHOKePQoPcXDqkC5cOOfjxqhcP6sJb3+Tw3JLtnN+/E5MzujK2Z0c+Wp/LYx9s5NZ/rzxsH5dndOVXlw4gMdouyzWByZctiCnARFX9kff9DcBoVb39kOVuA34OhADnqepmbwtiLU4LpBT4tap+1sw+ZgIzAVJTU0fs2LHDJ8di2jdPfQMfrsvF06Ckd4ykc2wYzy/J4p+fbCUs2M1N49K5aGBn+neJPqFLa1WVGk8DNZ4GRCAmzB6ravzPX6eYWhUQTZa/DrhIVaeLSCgQpaoFIjICmAsMPKTFcRA7xWTa2pa8ch56Zx2fbc5HFZLjwhmdHk9qQgSp8RH0Toqmf5dogtwtj0RaXVfPnz7cxLNfbKeu/sD/b6PS45kyIoVLBnch6nR41oZpl/wVEGcAD6rqRd739wOo6v8eYXkXUKSqsc3MWwz8QlWPmAAWEMZX8sqqWbQhjw/X5bFudwl7SqsbH7EdEeJmeGoH0jtGUlHroazaQ4jbxdheCZzdO5HS6jp+/uq3bMwt44phyfRKiiIs2E1pVR1vf7ubbfsqiAhx8+drM7jokOeDHzqcSUF5Da+vyOb/VmRTVFFLaJCL0GA3nWJC6dspmj6do+nbKZp+XWIscEyr+SsggnBOEZ0P5OB0Ul+nqmubLNNbVTd7f/4e8ICqZopIIlCoqvUi0gP4DBisqoVH2p8FhDlZquvqyS6qYt2eUpZnFbJ0eyF7SqqJCg0iOiyI0qo6dpc4o6eKQMeoUP4wZQjn9k06aDuqysqdxTz0zjrW5pTwj+uGM3FQZ1SVN1fm8NA766hvUDrFhBIfGcKqXcXU1Ssj0zrQp1M0tZ4Gqj0N5BRVsim3nPIaT+O2U+MjmNC/E/dO7EtYsF3ea47Mn5e5XgL8Becy19mq+oiIPAQsV9V5IvJXYAJQBxQBt6vqWhG5CnjIO70BJzjebmlfFhDmVKGqbM2v4NNN+RRU1PCjM3vQITLkiMuXVtcxffZSvssu4XdXDmbRhjzeW7OXzO4dGJQcS25pNXllNQxOjuW60an06RTd7D5ziqvYuLeM9XtKWZ1dwgfrchnYNYYnrx9BakLECR9XfYOyOruYvp2jiQixFkp7YTfKGXOKK/OGxMqdxQS7hbsv7MvNZ/U4ofszPlqfy12vrkKBX1zYl9SECBIiQyit8vDJpjwWb8ynoKKWH5/TkxvHdm/xRsI1OSX8au4avt1VTHxkCD86K50bz0gjPNjNrsJKNuWW8V1OCat2FbNudynDUjvwy0v6HXFMLXPqsIAw5jRQVl3HPz/ZyiWDuzCw62FdccdlV2ElP3lpJd/llBw0PcTtYlR6PCLw2eZ9dE+I4I7zepMaH0FkqJsQt4t95bXklVWzdHshryzdSXxkKD8Z35NPNuXzyaZ8okKDqKt3rsoCcLvE6QvpFMXC9XlU19UzfWwaFwzoRK2ngVpPA0kxoQzoEnPUjn2AFTuK+HhDLslxEaR3jKRv52jiW2iJmeNjAWFMAKtvUHYWVlJYUUthRS1BbmFUWjyR3o7sTzbl88i769iUW97s+i6BG8Z05+6L+jZemvvtrmJe/non0WFB9OkUTa9OUfTvHNN4P0p+WQ1/+nAjc5bt4tCvmIgQNxnd4uidFEV0WDBRYUGkxkdwVu+ORIcFU11Xz58/3MSsz7YdtG6wW7jnor786MweuFyCqvL26j28uTKbhyYNOuJptJ0FlfzohWV0jg1n4sDOXDiwkw0534QFhDGmRZ76BtbuLqWs2kN5jYfa+gY6RoaQFBNG59iw474qavu+CvYUVxES5CLY7WJnYSUrdhSxLKuQ7KIqyqrr8I6GQojbxRk9E9hTUsWm3HKmjerG/Zf0p7Sqjqx9lfz7qx28v3YvZ/bqyB3n9eJvH2/miy0FAAxKjuH1W8ce1iGfV1bN1f/8kuLKOmLDg9lZWIlL4GcT+nDn+b0PWnb9nlJ2FVaS3CGclA4RxIYHxn0qFhDGmFOSqlJZW8+6PaV8sHZv4w2LD18+qNmrvl5dtov/fnsdVXX1RIcFce9FfUmKCeOWF1dww5juPHz5gdF5SqvrmPqvr9i+r4KXbx5NRrc4Nuwt4/FFW3hn9R4e/N4AZoxLB+DNldnc+/pqPA0Hvg+T48IZ3zeR8/olMTI9vrH1VN+gLNm6j7e+ySG/rIbvj+nOBf07nbZPTLSAMMa0G1vzy3l39R6mjUptHAbld/PXM+vTbfx92jDO7ZfE19sKeHLxVlbtKuaZGSM5p09i4/qe+gZ+8tJKPliXy1+nZpBbWs3v5m9gbM8EfnFRX/aWVJNdVMnyrCI+37KPylrn+SMxYUEkd4igoLyGvLIaosOCiAkLJqe4il5JUVw1PIWqWg/55bWEuIW7LuhDXMSBPpPyGg/zVu3mksGdD5p+ol78agelVXXcdm6v41rfAsIY067V1TcwddZXfJdTQkOD4mlQwoPdPDplCJOGdj1s+eq6eqbPXsrSrEJU4dIhXfjTNUMPu5KrxlPP0u2FrN1dSk5RFTnFVYQGufje0K6c1y+JIJcwf81enlzsDAYpAvERIZRW19E9IZLnbxpFclw4uworufmF5WzYW0anmFD+MGVoY2htyi3jve/2Eh8ZzICuMfTt3LobHVWVPy/czN8+2syE/p341w0jjuuqNwsIY0y7t6ekit/+Zy29kqI4q1dHhnfv0OJNgqXVddz20kr6d4nhvon9TugUkapSVFlHTFgQQW4XX20r4OYXlhMR4ubuC/vy6HsbqK1v4N6J/XhhSRab88q5PKMrOwor+WZn8WHbCw1yEeJ2ERrsol/nGM7rl8T5/ZPonuAMeV/foPzmP2t4+eudXJOZwu+uGNyqK8OaYwFhjDEn2ca9ZUyfvZS9pdWkd4zk6emZ9EyMorqunscWbOSZL7bTKzGKa0d24/JhydR6Gli/p5QNe8soraqjtr6B6rp6lmcVsTnPucIsLNhFVGgQLhHyymr48fie3HtR3xMaRNICwhhj/GB3cRWvr8jmxjO6H9bvUFnrITzY3aov9x0FFSzemE9OcRXlNR4qajyM69WRazK7nXCNFhDGGGOa1VJAHN9JK2OMMe2eBYQxxphmWUAYY4xplgWEMcaYZllAGGOMaZYFhDHGmGZZQBhjjGmWBYQxxphmtZsb5UQkH9hxApvoCOxro3JOF4F4zBCYxx2IxwyBedzHeszdVTWxuRntJiBOlIgsP9LdhO1VIB4zBOZxB+IxQ2Aed1ses51iMsYY0ywLCGOMMc2ygDhglr8L8INAPGYIzOMOxGOGwDzuNjtm64MwxhjTLGtBGGOMaZYFhDHGmGYFfECIyEQR2SgiW0TkPn/X4ysi0k1EFonIOhFZKyI/9U6PF5EPRWSz998O/q61rYmIW0S+EZF3vO/TReRr72f+qoiEHG0bpxsRiROR10Vkg4isF5Ez2vtnLSJ3ef/bXiMir4hIWHv8rEVktojkiciaJtOa/WzF8Tfv8a8WkeHHsq+ADggRcQOPAxcDA4BpIjLAv1X5jAe4W1UHAGOA27zHeh/wkar2Bj7yvm9vfgqsb/L+UeDPqtoLKAJ+6JeqfOuvwPuq2g8YinP87fazFpFk4E4gU1UHAW5gKu3zs34OmHjItCN9thcDvb2vmcCTx7KjgA4IYBSwRVW3qWotMAeY7OeafEJV96jqSu/PZThfGMk4x/u8d7Hngcv9UqCPiEgKcCnwtPe9AOcBr3sXaY/HHAucDTwDoKq1qlpMO/+sgSAgXESCgAhgD+3ws1bVT4HCQyYf6bOdDLygjq+AOBHp0tp9BXpAJAO7mrzP9k5r10QkDRgGfA10UtU93ll7gU7+qstH/gLcCzR43ycAxarq8b5vj595OpAPPOs9tfa0iETSjj9rVc0BHgN24gRDCbCC9v9Z73ekz/aEvuMCPSACjohEAW8AP1PV0qbz1Lnmud1c9ywilwF5qrrC37WcZEHAcOBJVR0GVHDI6aR2+Fl3wPlrOR3oCkRy+GmYgNCWn22gB0QO0K3J+xTvtHZJRIJxwuElVX3TOzl3f5PT+2+ev+rzgXHAJBHJwjl9eB7Oufk472kIaJ+feTaQrapfe9+/jhMY7fmzngBsV9V8Va0D3sT5/Nv7Z73fkT7bE/qOC/SAWAb09l7pEILTqTXPzzX5hPfc+zPAelX9U5NZ84Dp3p+nA/852bX5iqrer6opqpqG89l+rKrXA4uAKd7F2tUxA6jqXmCXiPT1TjofWEc7/qxxTi2NEZEI73/r+4+5XX/WTRzps50H3Oi9mmkMUNLkVNRRBfyd1CJyCc55ajcwW1Uf8W9FviEiZwKfAd9x4Hz8L3H6IV4DUnGGS79GVQ/tADvtich44BeqepmI9MBpUcQD3wDfV9UaP5bX5kQkA6djPgTYBvwA5w/CdvtZi8h/A9fiXLH3DfAjnPPt7eqzFpFXgPE4w3rnAg8Ac2nms/WG5T9wTrdVAj9Q1eWt3legB4QxxpjmBfopJmOMMUdgAWGMMaZZFhDGGGOaZQFhjDGmWRYQxhhjmmUBYYwficj4/aPMGnOqsYAwxhjTLAsIY1pBRL4vIktFZJWI/Mv7jIlyEfmz9xkEH4lIonfZDBH5yjv+/ltNxubvJSILReRbEVkpIj29m49q8uyGl7w3NyEivxfn+R2rReQxPx26CWAWEMYchYj0x7lDd5yqZgD1wPU4A8ItV9WBwCc4d7QCvAD8l6oOwblzff/0l4DHVXUoMBZn1FFwRtb9Gc4zSXoA40QkAbgCGOjdzv/48hiNaY4FhDFHdz4wAlgmIqu873vgDFnyqneZfwNnep/FEKeqn3inPw+cLSLRQLKqvgWgqtWqWuldZqmqZqtqA7AKSMMZrroaeEZErsQZJsGYk8oCwpijE+B5Vc3wvvqq6oPNLHe849Y0HRuoHgjyPsNgFM5IrJcB7x/nto05bhYQxhzdR8AUEUmCxuf/dsf5/2f/SKHXAZ+raglQJCJneaffAHzifYpftohc7t1GqIhEHGmH3ud2xKrqfOAunMeGGnNSBR19EWMCm6quE5FfAx+IiAuoA27DeRDPKO+8PJx+CnCGW/6nNwD2j6QKTlj8S0Qe8m7j6hZ2Gw38R0TCcFowP2/jwzLmqGw0V2OOk4iUq2qUv+swxlfsFJMxxphmWQvCGGNMs6wFYYwxplkWEMYYY5plAWGMMaZZFhDGGGOaZQFhjDGmWf8fQgodCr9AX4QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "#plt.ylim([0, 100])\n",
    "plt.plot(history_df['epoch'], history_df['loss'], label='Training')\n",
    "plt.plot(history_df['epoch'], history_df['val_loss'], label='Validation', linestyle='dashed')\n",
    "plt.legend(loc='upper center', shadow=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 592us/step - loss: 0.3512 - binary_accuracy: 0.8432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3512304127216339, 0.8432080745697021]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a fan film that for the uninitiated plays better on video with the sound turned down: 0\n",
      "a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films: 1\n",
      "I'm happy to be here: 1\n",
      "i got scared: 0\n",
      "i'm sick: 0\n",
      "today is a beautiful day: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\n",
    "    \"a fan film that for the uninitiated plays better on video with the sound turned down\",\n",
    "    \"a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\",\n",
    "    \"I'm happy to be here\", \n",
    "    \"i got scared\", \"i'm sick\", \n",
    "    \"today is a beautiful day\"]\n",
    "\n",
    "tokenized = tokenize(sentences)\n",
    "padded = pad_tokens(tokenized, max_len)\n",
    "attention_mask = get_attention_mask(padded)\n",
    "attention_mask = tf.convert_to_tensor(attention_mask, dtype=tf.int32)\n",
    "input_ids = tf.convert_to_tensor(padded, dtype=tf.int32)\n",
    "\n",
    "last_hidden_states = model(input_ids, attention_mask = attention_mask)\n",
    "\n",
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "predictions = lr_model.predict(features) > .5\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(f'{sentences[i]}: {int(predictions[i][0])}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c48d435e47ba5d5a932a530ddeb248c9baa0081132f1819dcaeedbf0fcd2e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
